{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams['font.size'] = 18\n",
    "\n",
    "import keras \n",
    "import tensorflow as tf\n",
    "\n",
    "from keras import models, layers, optimizers, losses, metrics, callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>era</th>\n",
       "      <th>data_type</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>...</th>\n",
       "      <th>feature42</th>\n",
       "      <th>feature43</th>\n",
       "      <th>feature44</th>\n",
       "      <th>feature45</th>\n",
       "      <th>feature46</th>\n",
       "      <th>feature47</th>\n",
       "      <th>feature48</th>\n",
       "      <th>feature49</th>\n",
       "      <th>feature50</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n2b2e3dd163cb422</td>\n",
       "      <td>era1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.43487</td>\n",
       "      <td>0.44645</td>\n",
       "      <td>0.25802</td>\n",
       "      <td>0.37149</td>\n",
       "      <td>0.62235</td>\n",
       "      <td>0.67451</td>\n",
       "      <td>0.68103</td>\n",
       "      <td>...</td>\n",
       "      <td>0.52962</td>\n",
       "      <td>0.42439</td>\n",
       "      <td>0.51680</td>\n",
       "      <td>0.46297</td>\n",
       "      <td>0.57426</td>\n",
       "      <td>0.57946</td>\n",
       "      <td>0.49646</td>\n",
       "      <td>0.48968</td>\n",
       "      <td>0.54194</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n177021a571c94c8</td>\n",
       "      <td>era1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.50038</td>\n",
       "      <td>0.39216</td>\n",
       "      <td>0.38394</td>\n",
       "      <td>0.51213</td>\n",
       "      <td>0.36660</td>\n",
       "      <td>0.46911</td>\n",
       "      <td>0.68204</td>\n",
       "      <td>...</td>\n",
       "      <td>0.51669</td>\n",
       "      <td>0.48445</td>\n",
       "      <td>0.57587</td>\n",
       "      <td>0.59860</td>\n",
       "      <td>0.67558</td>\n",
       "      <td>0.45577</td>\n",
       "      <td>0.80908</td>\n",
       "      <td>0.50287</td>\n",
       "      <td>0.61629</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n7830fa4c0cd8466</td>\n",
       "      <td>era1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.47416</td>\n",
       "      <td>0.34143</td>\n",
       "      <td>0.39528</td>\n",
       "      <td>0.46337</td>\n",
       "      <td>0.72953</td>\n",
       "      <td>0.45962</td>\n",
       "      <td>0.47869</td>\n",
       "      <td>...</td>\n",
       "      <td>0.41458</td>\n",
       "      <td>0.34804</td>\n",
       "      <td>0.29058</td>\n",
       "      <td>0.51382</td>\n",
       "      <td>0.36389</td>\n",
       "      <td>0.80602</td>\n",
       "      <td>0.39253</td>\n",
       "      <td>0.41821</td>\n",
       "      <td>0.58679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nc594a184cee941b</td>\n",
       "      <td>era1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.48759</td>\n",
       "      <td>0.55903</td>\n",
       "      <td>0.43987</td>\n",
       "      <td>0.38834</td>\n",
       "      <td>0.44650</td>\n",
       "      <td>0.46389</td>\n",
       "      <td>0.70749</td>\n",
       "      <td>...</td>\n",
       "      <td>0.28776</td>\n",
       "      <td>0.42881</td>\n",
       "      <td>0.55402</td>\n",
       "      <td>0.53695</td>\n",
       "      <td>0.48793</td>\n",
       "      <td>0.62432</td>\n",
       "      <td>0.52898</td>\n",
       "      <td>0.49009</td>\n",
       "      <td>0.49557</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nc5ab8667901946a</td>\n",
       "      <td>era1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.23433</td>\n",
       "      <td>0.55499</td>\n",
       "      <td>0.47849</td>\n",
       "      <td>0.56990</td>\n",
       "      <td>0.64945</td>\n",
       "      <td>0.47152</td>\n",
       "      <td>0.62085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.64405</td>\n",
       "      <td>0.32416</td>\n",
       "      <td>0.33193</td>\n",
       "      <td>0.58065</td>\n",
       "      <td>0.44587</td>\n",
       "      <td>0.47770</td>\n",
       "      <td>0.44020</td>\n",
       "      <td>0.47895</td>\n",
       "      <td>0.57978</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id   era data_type  feature1  feature2  feature3  feature4  \\\n",
       "0  n2b2e3dd163cb422  era1     train   0.43487   0.44645   0.25802   0.37149   \n",
       "1  n177021a571c94c8  era1     train   0.50038   0.39216   0.38394   0.51213   \n",
       "2  n7830fa4c0cd8466  era1     train   0.47416   0.34143   0.39528   0.46337   \n",
       "3  nc594a184cee941b  era1     train   0.48759   0.55903   0.43987   0.38834   \n",
       "4  nc5ab8667901946a  era1     train   0.23433   0.55499   0.47849   0.56990   \n",
       "\n",
       "   feature5  feature6  feature7   ...    feature42  feature43  feature44  \\\n",
       "0   0.62235   0.67451   0.68103   ...      0.52962    0.42439    0.51680   \n",
       "1   0.36660   0.46911   0.68204   ...      0.51669    0.48445    0.57587   \n",
       "2   0.72953   0.45962   0.47869   ...      0.41458    0.34804    0.29058   \n",
       "3   0.44650   0.46389   0.70749   ...      0.28776    0.42881    0.55402   \n",
       "4   0.64945   0.47152   0.62085   ...      0.64405    0.32416    0.33193   \n",
       "\n",
       "   feature45  feature46  feature47  feature48  feature49  feature50  target  \n",
       "0    0.46297    0.57426    0.57946    0.49646    0.48968    0.54194       1  \n",
       "1    0.59860    0.67558    0.45577    0.80908    0.50287    0.61629       0  \n",
       "2    0.51382    0.36389    0.80602    0.39253    0.41821    0.58679       0  \n",
       "3    0.53695    0.48793    0.62432    0.52898    0.49009    0.49557       0  \n",
       "4    0.58065    0.44587    0.47770    0.44020    0.47895    0.57978       0  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('numerai_datasets/numerai_training_data.csv')\n",
    "test = pd.read_csv('numerai_datasets/numerai_tournament_data.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(train, test):\n",
    "    features = [f for f in list(train) if \"feature\" in f]\n",
    "    X = train[features]\n",
    "    Y = train['target']\n",
    "    X_prediction = test[features]\n",
    "    ids = test['id']\n",
    "    \n",
    "    pca = PCA(n_components=0.95)\n",
    "    X = pca.fit_transform(X)\n",
    "    X_prediction = pca.transform(X_prediction)\n",
    "    \n",
    "    model = ExtraTreesClassifier(n_estimators = 100, verbose = 1, n_jobs=-1)\n",
    "    # model = LogisticRegression(n_jobs=-1)\n",
    "    model.fit(X, Y)\n",
    "    \n",
    "    predictions = model.predict_proba(X_prediction)\n",
    "    probabilities = predictions[:, 1]\n",
    "    \n",
    "    results_df = pd.DataFrame({'probability': probabilities})\n",
    "    results_df = pd.DataFrame(ids).join(results_df)\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model(train, test)\n",
    "results.to_csv('numerai_extratrees.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    val_loss = history.history['val_loss']\n",
    "    train_loss = history.history['loss']\n",
    "    epochs = [int(i) for i in list(range(1, len(val_loss) + 1))]\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    \n",
    "    plt.plot(epochs, train_loss, 'bo-', label = 'training loss')\n",
    "    plt.plot(epochs, val_loss, 'ro-', label = 'validation loss')\n",
    "    plt.xlabel('Epoch'); plt.ylabel('Log Loss'); plt.title('Training Curves')\n",
    "    plt.legend();\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [f for f in list(train) if \"feature\" in f]\n",
    "X = train[features]\n",
    "Y = train['target']\n",
    "X_test = test[features]\n",
    "\n",
    "X_valid = test.ix[test['data_type'] == 'validation', features]\n",
    "Y_valid = test.ix[test['data_type'] == 'validation', 'target']\n",
    "ids = test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 0.99)\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X = pca.fit_transform(X)\n",
    "X_valid = pca.transform(X_valid)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "X = scaler.fit_transform(X)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(32, activation = 'elu', input_dim = X.shape[1]))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(64, activation = 'elu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(128, activation = 'elu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(64, activation = 'elu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(32, activation = 'elu'))\n",
    "model.add(layers.Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(loss = losses.binary_crossentropy,\n",
    "              metrics = [losses.binary_crossentropy],\n",
    "              optimizer = optimizers.SGD())\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_list = [callbacks.ModelCheckpoint(filepath='models/numerai_nn.hdf5', save_best_only = True, monitor = 'val_loss'),\n",
    "                callbacks.EarlyStopping(monitor = 'val_loss', patience = 3)]\n",
    "\n",
    "history = model.fit(X, Y, epochs = 25, batch_size = 1024, \n",
    "                    validation_data = [X_valid, Y_valid], callbacks=callback_list)    \n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('models/numerai_nn.hdf5')\n",
    "p_array = model.predict(X_prediction)\n",
    "p = p_array[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'id': ids, 'probability': p})\n",
    "results.to_csv('numerai_nn.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traditional Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs = pd.Series(train.corr()['target'].sort_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_corrs = corrs[abs(corrs.values) > 0.01]\n",
    "top_corrs_names = list(top_corrs.index)\n",
    "top_corrs_names.remove('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = [f for f in list(train) if \"feature\" in f]\n",
    "features = top_corrs_names\n",
    "X = train[features]\n",
    "Y = train['target']\n",
    "X_test = test[features]\n",
    "\n",
    "X_valid = test.ix[test['data_type'] == 'validation', features]\n",
    "Y_valid = test.ix[test['data_type'] == 'validation', 'target']\n",
    "ids = test['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LogisticRegressionCV(n_jobs=-1, cv = 3, Cs=50, scoring = 'log_loss')\n",
    "lr_model.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_valid_pred = lr_model.predict_proba(X_valid)[:, 1]\n",
    "print('Validation Log Loss using Logistic Regression = {:0.6f}.'.format(log_loss(Y_valid, lr_valid_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pred = lr_model.predict_proba(X_test)[:, 1]\n",
    "results = pd.DataFrame({'id': ids, 'probability': lr_pred})\n",
    "results.to_csv('submissions/101/lr_cv.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_valid_pred = gnb.predict_proba(X_valid)[:, 1]\n",
    "print('Validation Log Loss using Logistic Regression = {:0.6f}.'.format(log_loss(Y_valid, gnb_valid_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_pred = gnb.predict_proba(X_test)[:, 1]\n",
    "results = pd.DataFrame({'id': ids, 'probability': gnb_pred})\n",
    "results.to_csv('submissions/101/gnb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_valid = 0.8 * lr_valid_pred + 0.2 * gnb_valid_pred\n",
    "print('Validation Log Loss Combined = {:0.6f}.'.format(log_loss(Y_valid, combined_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_pred = 0.8 * lr_pred + 0.2 * gnb_pred\n",
    "results = pd.DataFrame({'id': ids, 'probability': combined_pred})\n",
    "results.to_csv('submissions/101/lr_gnb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [f for f in list(train) if \"feature\" in f]\n",
    "# features = top_corrs_names\n",
    "X = train[features]\n",
    "Y = train['target']\n",
    "X_test = test[features]\n",
    "\n",
    "X_valid = test.ix[test['data_type'] == 'validation', features]\n",
    "Y_valid = test.ix[test['data_type'] == 'validation', 'target']\n",
    "ids = test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model2 = LogisticRegressionCV(n_jobs=-1, cv = 3, Cs=50, scoring = 'log_loss')\n",
    "lr_model2.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_valid_pred2 = lr_model2.predict_proba(X_valid)[:, 1]\n",
    "print('Validation Log Loss using Logistic Regression = {:0.6f}.'.format(log_loss(Y_valid, lr_valid_pred2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_valid_pred = lr_model.predict_proba(X_valid)[:, 1]\n",
    "print('Validation Log Loss using Logistic Regression = {:0.6f}.'.format(log_loss(Y_valid, lr_valid_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss(Y_valid, [0.5 for _ in range(len(Y_valid))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-np.log(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = lr_model.predict_proba(X_test)[:, 1]\n",
    "results = pd.DataFrame({'id': ids, 'probability': p})\n",
    "results.to_csv('submissions/numerai4.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_X = train[features]\n",
    "full_X_test = test[features]\n",
    "full_X_valid = test.ix[test['data_type'] == 'validation', features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(probability=True)\n",
    "svm.fit(full_X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_valid_pred = svm.predict_proba(full_X_valid)[:, 1]\n",
    "print('Validation Log Loss using Support Vector Classifier = {:0.6f}.'.format(log_loss(Y_valid, svm_valid_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
